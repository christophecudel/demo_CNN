{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophecudel/demo_CNN/blob/main/TP%20CNN%20Multi_classes%20(full%20version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TP CNN Multi-classes (full version 12 Janvier 2026)**\n",
        "\n",
        "Chacune de ces cellules s'éxcutent de façon indépendantes. Enchainées, elles permettent :\n",
        "* Télécharger les données d'apprentissage (Dossiers Train et Test)\n",
        "* Préparer l'apparentissage (paramètres), l'architecture du CNN et lancer l'apprentissage (et aussi conclure sur l'évalution de valeurs de Loss et Accuracy durant l'apprentissage).\n",
        "* **Attention : l'architecture et les paramètres sont à ajuster pour chaque cas de figure**\n",
        "* Appliquer l'inférence sur des images du dossier \"Eval\"\n",
        "* Visualiser les résulats sur le dataset d'évaluation\n",
        "* Enregistrer le \"model\" du reseau, pour revenier à l'étape 3 à postériori"
      ],
      "metadata": {
        "id": "QlB2ZxeR04jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TP CNN Multi-classes\n",
        "# Chacune de ces cellules s'éxcutent de façon indépendantes\n",
        "# Enchainées, elles permettent :\n",
        "# 1. Télécharger les données d'apprentissage (Dossiers Train et Test)\n",
        "# 2. Préparer l'apparentissage (paramètres), l'architecture du CNN et lancer l'apprentissage\n",
        "# 3. Appliquer l'inférence sur des images du dossier \"Eval\"\n",
        "# 4. Visualiser les résulats sur le dataset d'évaluation\n",
        "\n",
        "# Etape 1 : organniser les données pour les rendre\n",
        "## compatibles avec l'apprentissage du CNN\n",
        "\n",
        "# Organniser les dossiers comme suit :\n",
        "# DataBase |- Train |---- Classe_0\n",
        "#          |        |---- Classe_1\n",
        "#          |        |............\n",
        "#          |        |---- Classe_N\n",
        "#          |\n",
        "#          |-- Test |---- Classe_0\n",
        "#          |        |---- Classe_1\n",
        "#          |        |............\n",
        "#          |        |---- Classe_N\n",
        "\n",
        "\n",
        "# A partir des images \"Classe_0\", \"Classe_1\", etc.... :\n",
        "# Environ 80% des images vont dans Train\n",
        "# et 20% dans Test\n",
        "\n",
        "# Une fois le dossier correctement constitué :\n",
        "# - faire un .zip\n",
        "# - télécharger le .zip avec la ligne ci-dessous\n",
        "\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "SfMsphjPAank"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# le fichier est décompressé dans l'envirronnement local\n",
        "#!unzip Ex01_3_Classes_DataToTrainCNN.zip # >> my_images_base.zip est le nom de votre fichier qui a été téléchargé\n",
        "!unzip Ex04_6_Classes_RawData_DiceHard_DataToTrainCNN.zip\n"
      ],
      "metadata": {
        "id": "lXbdEqBhkBsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Lister le contenu de DataBase_05\n",
        "# Attention au respect des Majuscules minuscules\n",
        "#os.listdir(\"/content/Ex01_3_Classes_DataToTrainCNN\")\n",
        "os.listdir(\"/content/Ex04_6_Classes_RawData(DiceHard)_DataToTrainCNN\")\n"
      ],
      "metadata": {
        "id": "fwxL11sMq2d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1o8IWdoh8Bd"
      },
      "outputs": [],
      "source": [
        "# Etape 2 : préparer l'apprentissage\n",
        "# précisant bien les dossiers à prendre en compte :\n",
        "# chemins vers vos dossiers d'images d'entraînement et de test\n",
        "# depuis l'environnement google colab\n",
        "train_data_dir = \"/content/Ex04_6_Classes_RawData(DiceHard)_DataToTrainCNN/Train\" # par exemple - à ajuster\n",
        "test_data_dir =  \"/content/Ex04_6_Classes_RawData(DiceHard)_DataToTrainCNN/Test\" # par exemple - à ajuster\n",
        "\n",
        "# Ici, on vérifie que l'accès aux images est OK :\n",
        "images_dir = \"/content/Ex04_6_Classes_RawData(DiceHard)_DataToTrainCNN/Train/Dice_1/*.bmp\"\n",
        "images_name = glob.glob(images_dir)\n",
        "print(images_name)\n",
        "print(\"first and last images name : \",images_name[0],\",\", images_name[-1])\n",
        "\n",
        "# Si l'instruction ne retourne pas les noms de fichier\n",
        "# de la 1ère et dernière image : revoir les étapes pér\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Etape 3 :On affiche les dimensions des images\n",
        "from PIL import Image\n",
        "\n",
        "# Ouvrir l'image PNG\n",
        "image = Image.open(images_name[0])\n",
        "\n",
        "# Obtenir les dimensions de l'image\n",
        "NbCols, NbRows = image.size\n",
        "\n",
        "if image.mode == 'RGB':\n",
        "    NbCanaux = 3\n",
        "elif image.mode == 'L':\n",
        "    NbCanaux = 1\n",
        "else:\n",
        "    NbCanaux = 'Inconnu'  # Pour d'autres modes, la gestion peut être ajoutée selon les besoins\n",
        "\n",
        "# Afficher les informations\n",
        "print(f'Nombre de colonnes (largeur): {NbCols}, Nombre de lignes (hauteur): {NbRows}, Nombre de canaux: {NbCanaux}')\n"
      ],
      "metadata": {
        "id": "rkOgA-baOfOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uJB6qrMZcus"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Etape 4 : apprentissage\n",
        "# Préparation des paramètres pour la\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Créez des générateurs de données pour l'entraînement et le test\n",
        "image_size = (NbRows, NbCols)\n",
        "batch_size = 16\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255 ,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # N classes : déduit du nombre de sous-dossiers dans train_data_dir\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Créez un générateur de données pour charger et prétraiter les images de test\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # même type de sortie que pour l'entraînement\n",
        "    shuffle=False  # Vous pouvez désactiver le mélange pour garder l'ordre\n",
        ")\n",
        "\n",
        "# N = nombre de classes détectées automatiquement à partir des sous-dossiers\n",
        "num_classes = train_generator.num_classes\n",
        "print(\"Nombre de classes (N) :\", num_classes)\n",
        "print(\"Indices des classes :\", train_generator.class_indices)\n",
        "\n",
        "# Créez un modèle CNN\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(NbRows, NbCols, 3)),  # Déclaration de l'entrée ici\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(NbRows, NbCols, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')  # N classes, décision multi-classes\n",
        "])\n",
        "\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#early_stop = keras.callbacks.EarlyStopping(\n",
        "#    monitor=\"val_loss\",\n",
        "#    patience=80,\n",
        "#    min_delta=0.01,\n",
        "#    restore_best_weights=True\n",
        "#)\n",
        "\n",
        "# Entraîner le modèle\n",
        "num_epochs = 300\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data=test_generator)#,\n",
        "                    #callbacks=[early_stop])\n",
        "\n",
        "# Évaluer le modèle sur l'ensemble de test\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Accuracy on test set: {test_acc}')\n",
        "\n",
        "# Sauvegarder le modèle si nécessaire\n",
        "# ces lignes demandent une durée d'excécution non négligeables\n",
        "# elles sont nécessaires si on excecute le \"model\" de CNN dans un autre code\n",
        "# il faut alors re-charger le \"model\" de CNN\n",
        "# chaine = f\"content/Classif_keras_{num_epochs:02d}_epochs\"\n",
        "# model.save(chaine)\n",
        "\n",
        "# Afficher les courbes de loss et d'accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHW_oknRNoys",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Etape 5 : le modèle est testé sur des images\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Spécifiez le chemin du dossier contenant les images à prédire\n",
        "#images_directory = \"/content/Ex01_3_Classes_DataToTrainCNN/Eval\"\n",
        "images_directory = \"/content/Ex04_6_Classes_RawData(DiceHard)_DataToTrainCNN/Eval\"\n",
        "\n",
        "# Créez des listes pour stocker les images, les prédictions et les noms de fichiers\n",
        "images = []\n",
        "predictions = []\n",
        "image_names = []\n",
        "\n",
        "# Récupérer la correspondance indice -> nom de classe à partir du générateur d'entraînement\n",
        "class_indices = train_generator.class_indices           # dict : nom_de_classe -> indice\n",
        "idx_to_class = {v: k for k, v in class_indices.items()} # dict : indice -> nom_de_classe\n",
        "\n",
        "# Parcourez les fichiers d'images dans le dossier\n",
        "for filename in os.listdir(images_directory):\n",
        "    if filename.lower().endswith('.bmp'):\n",
        "        # Charger l'image pour la prédiction\n",
        "        image_path = os.path.join(images_directory, filename)\n",
        "        img = image.load_img(image_path, target_size=(NbRows, NbCols))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array /= 255.0  # Assurez-vous de normaliser l'image comme pendant l'entraînement\n",
        "\n",
        "        # Faire la prédiction : vecteur de probabilités de taille N (num_classes)\n",
        "        proba = model.predict(img_array, verbose=0)[0]\n",
        "\n",
        "        # Stocker les résultats\n",
        "        predictions.append(proba)\n",
        "        images.append(img)\n",
        "        image_names.append(filename)\n",
        "\n",
        "        # Afficher la classe prédite dans la console (optionnel)\n",
        "        pred_class_idx = np.argmax(proba)\n",
        "        pred_class_name = idx_to_class[pred_class_idx]\n",
        "        print(f\"{filename} -> classe prédite : {pred_class_name}, proba = {proba[pred_class_idx]:.3f}\")\n",
        "\n",
        "# Afficher le nombre total d'images traitées\n",
        "print(\"Nombre d'images traitées :\", len(images))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionnel :\n",
        "# Recharger un modèle (ici : Ex01_3_Classes_Model.keras)\n",
        "from tensorflow import keras\n",
        "#model = keras.models.load_model(\"/content/drive/MyDrive/Ex01_3_Classes_Model.keras\")\n"
      ],
      "metadata": {
        "id": "BguWjdTkKyg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVNPVzFUKBoI"
      },
      "outputs": [],
      "source": [
        "# Etape 5 : visualisation des résultats sur les images de test\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# On suppose que les listes 'images', 'predictions' et 'image_names'\n",
        "# ont été remplies dans l'étape 5.\n",
        "\n",
        "# Récupérer (au cas où) la correspondance indice -> nom de classe\n",
        "class_indices = train_generator.class_indices\n",
        "idx_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "# Créer un widget Output pour l'affichage des images\n",
        "output = widgets.Output()\n",
        "\n",
        "# Créer un slider\n",
        "slider = widgets.IntSlider(min=0, max=len(images) - 1, step=1, description='Image Index:')\n",
        "\n",
        "# Fonction pour mettre à jour l'image et le nom\n",
        "def update_image(change):\n",
        "    img_index = change['new']  # Utilisation de change['new'] au lieu de change.new\n",
        "    with output:\n",
        "        clear_output(wait=True)  # Effacer l'affichage précédent\n",
        "        plt.figure(figsize=(5,5))  # Ajustez la taille si nécessaire\n",
        "        plt.imshow(images[img_index])  # Afficher la nouvelle image\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Récupérer le vecteur de probabilités pour cette image\n",
        "        proba = predictions[img_index]\n",
        "        pred_class_idx = int(np.argmax(proba))\n",
        "        classe = idx_to_class[pred_class_idx]\n",
        "\n",
        "        plt.title(image_names[img_index] + ' : ' + classe, fontsize=12)\n",
        "        plt.show()\n",
        "\n",
        "# Observer les changements du slider\n",
        "slider.observe(update_image, names='value')\n",
        "\n",
        "# Afficher le slider et la zone d'affichage\n",
        "display(slider)\n",
        "display(output)\n",
        "\n",
        "# Affichage initial\n",
        "update_image({'new': slider.value})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour sauver le modèle\n",
        "model.save('/content/Ex01_3_Classes_Model_1000epochs.keras')\n"
      ],
      "metadata": {
        "id": "hd3GqGqJJxzA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "demo_cnn_01 (N Classes).ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}