{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophecudel/demo_CNN/blob/main/demo_cnn_01_(N_Classes).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Etape 1 : organniser les données pour les rendre\n",
        "## compatibles avec l'apprentissage du CNN\n",
        "\n",
        "# Organniser les dossiers comme suit :\n",
        "# DataBase |- Train |---- Classe_0\n",
        "#          |        |---- Classe_1\n",
        "#          |-- Test |---- Classe_0\n",
        "#                   |---- Classe_1\n",
        "\n",
        "# A partir des images \"Classe_0\" et \"Classe_1\" :\n",
        "# Environ 80% des images vont dans Train\n",
        "# et 20% dans Test\n",
        "\n",
        "# Une fois le dossier correctement constitué :\n",
        "# - faire un .zip\n",
        "# - télécharger le .zip avec la ligne ci-dessous\n",
        "\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "SfMsphjPAank"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# le fichier est décompressé dans l'envirronnement local\n",
        "!unzip DataBase_05.zip # >> my_images_base.zip est le nom de votre fichier qui a été téléchargé"
      ],
      "metadata": {
        "id": "lXbdEqBhkBsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Lister le contenu de DataBase_05\n",
        "# Attention au respect des Majuscules minuscules\n",
        "os.listdir(\"/content/DataBase_05\")\n"
      ],
      "metadata": {
        "id": "fwxL11sMq2d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1o8IWdoh8Bd"
      },
      "outputs": [],
      "source": [
        "# Etape 2 : préparer l'apprentissage\n",
        "# précisant bien les dossiers à prendre en compte :\n",
        "# chemins vers vos dossiers d'images d'entraînement et de test\n",
        "# depuis l'environnement google colab\n",
        "train_data_dir = \"DataBase_05/train\" # par exemple - à ajuster\n",
        "test_data_dir = \"DataBase_05/test\" # par exemple - à ajuster\n",
        "\n",
        "# Ici, on vérifie que l'accès aux images est OK :\n",
        "images_dir = \"../content/DataBase_05/train/Classe_0/*.bmp\"\n",
        "images_name = glob.glob(images_dir)\n",
        "print(images_name)\n",
        "#print(\"first and last images name : \",images_name[0],\",\", images_name[-1])\n",
        "\n",
        "# Si l'instruction ne retourne pas les noms de fichier\n",
        "# de la 1ère et dernière image : revoir les étapes pér\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Etape 3 :On affiche les dimensions des images\n",
        "from PIL import Image\n",
        "\n",
        "# Ouvrir l'image PNG\n",
        "image = Image.open(images_name[0])\n",
        "\n",
        "# Obtenir les dimensions de l'image\n",
        "NbCols, NbRows = image.size\n",
        "\n",
        "if image.mode == 'RGB':\n",
        "    NbCanaux = 3\n",
        "elif image.mode == 'L':\n",
        "    NbCanaux = 1\n",
        "else:\n",
        "    NbCanaux = 'Inconnu'  # Pour d'autres modes, la gestion peut être ajoutée selon les besoins\n",
        "\n",
        "# Afficher les informations\n",
        "print(f'Nombre de colonnes (largeur): {NbCols}, Nombre de lignes (hauteur): {NbRows}, Nombre de canaux: {NbCanaux}')\n"
      ],
      "metadata": {
        "id": "rkOgA-baOfOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uJB6qrMZcus"
      },
      "outputs": [],
      "source": [
        "# Etape 4 : apprentissage\n",
        "# Préparation des paramètres pour la\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Créez des générateurs de données distincts pour chaque classe d'entraînement\n",
        "image_size = (NbRows, NbCols)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Deux classes : classe_0 et classe_1\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# S'il y a plus de classes, il ne faut plus être en \"class_mode\".\n",
        "# Fusionnez les générateurs de données en un seul pour l'entraînement en utilisant numpy\n",
        "#train_generator = np.concatenate([train_generator_classe_0, train_generator_classe_1])\n",
        "\n",
        "# Créez un générateur de données pour charger et prétraiter les images de test\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Deux classes : classe_0 et classe_1\n",
        "    shuffle=False  # Vous pouvez désactiver le mélange pour garder l'ordre\n",
        ")\n",
        "\n",
        "# Créez un modèle CNN\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(NbRows, NbCols, 3)),  # Déclaration de l'entrée ici\n",
        "    #layers.Conv2D(32, (3, 3), activation='relu', input_shape=(NbRows, NbCols, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Deux classes : classe_0 et classe_1 (décision binaire)\n",
        "])\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "num_epochs = 100\n",
        "\n",
        "history = model.fit(train_generator, epochs=num_epochs, validation_data=test_generator)\n",
        "\n",
        "# Évaluer le modèle sur l'ensemble de test\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Accuracy on test set: {test_acc}')\n",
        "\n",
        "# Sauvegarder le modèle si nécessaire\n",
        "# ces lignes demandent une durée d'excécution non négligeables\n",
        "# elles sont nécessaires si on excecute le \"model\" de CNN dans un autre code\n",
        "# il faut alors re-charger le \"model\" de CNN\n",
        "# chaine = f\"content/Classif_keras_{num_epochs:02d}_epochs\"\n",
        "# model.save(chaine)\n",
        "\n",
        "# Afficher les courbes de loss et d'accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX1Jjeq5-3Sp"
      },
      "outputs": [],
      "source": [
        "# Etape facultative\n",
        "# Uniquement si le \"model\" est excuté dans un autre notebook jupyter\n",
        "# ou bien dans un autre contexte\n",
        "# étape très longue\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Sauvegarder le modèle (CNN) si nécessaire\n",
        "dossier = f\"/models/Classif_keras_{num_epochs:02d}_epochs\"\n",
        "print(\"Dossier du modèle à télécharger :\" + dossier)\n",
        "model.save(dossier)\n",
        "\n",
        "# Créer un fichier ZIP\n",
        "mon_dossier_zip = dossier + \".zip\"\n",
        "# Créer un fichier ZIP\n",
        "with zipfile.ZipFile(mon_dossier_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, fichiers in os.walk(dossier):\n",
        "        for fichier in fichiers:\n",
        "            chemin_complet = os.path.join(root, fichier)\n",
        "            nom_dans_zip = os.path.relpath(chemin_complet, os.path.dirname(dossier))\n",
        "            zipf.write(chemin_complet, nom_dans_zip)\n",
        "\n",
        "        # Ajouter également les dossiers vides\n",
        "        if not fichiers:\n",
        "            nom_dossier_vide = os.path.relpath(root, os.path.dirname(dossier)) + '/'\n",
        "            zipf.write(root, nom_dossier_vide)\n",
        "\n",
        "# Télécharger le fichier ZIP\n",
        "files.download(mon_dossier_zip)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Etape : préparation pour visualiser le résultat de l'apprentissage\n",
        "# Les images ne doivent pas être celles utilisées pour l'apprentissage\n",
        "# donc prendre les images de test en préparant un fichier zip\n",
        "# le mieux est de mélanger des images de classe_0 et de classe_1 dans un même dossier\n",
        "\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "3-SRY1hMJLOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# le fichier est décompressé dans l'envirronnement local\n",
        "!unzip images_test.zip # >> images_test.zip est le nom de votre fichier qui a été téléchargé"
      ],
      "metadata": {
        "id": "0lWVJvd7kfi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHW_oknRNoys",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Etape 5 : le modèle est testé sur des images\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "\n",
        "# Spécifiez le chemin du dossier contenant les images à prédire\n",
        "images_directory = \"/content/Images_test\"\n",
        "\n",
        "#NbRows, NbCols = 128\n",
        "Count_classe_0, Count_classe_1 = 0,0\n",
        "\n",
        "# Créez une liste pour stocker les images et les prédictions\n",
        "images = []\n",
        "predictions = []\n",
        "\n",
        "# Parcourez les fichiers d'images dans le dossier\n",
        "for filename in os.listdir(images_directory):\n",
        "    if filename.endswith('.bmp'):\n",
        "        # Charger l'image pour la prédiction\n",
        "        image_path = os.path.join(images_directory, filename)\n",
        "        img = image.load_img(image_path, target_size=(NbRows, NbCols))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array /= 255.0  # Assurez-vous de normaliser l'image comme pendant l'entraînement\n",
        "\n",
        "       # Faire la prédiction\n",
        "        pred = model.predict(img_array)\n",
        "        predictions.append(pred[0][0])\n",
        "\n",
        "        # Stocker l'imagen sous forme d'un tableau\n",
        "        images.append(img)\n",
        "\n",
        "        # Afficher les images dans une seule figure avec une barre de défilement\n",
        "        num_images = len(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# si ipywidget n'est pas installé :\n",
        "# outil utilisé pour la visualisation dans l'étape suivante\n",
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "ojG7lzwKW3rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVNPVzFUKBoI"
      },
      "outputs": [],
      "source": [
        "# Etape 6 : visualisation des résultats sur les images de test\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supposons que vous avez une liste d'images et une liste de noms correspondants\n",
        "#images = [img1, img2, img3, ...]  # Remplacez ceci par vos images\n",
        "\n",
        "image_names = os.listdir(images_directory)\n",
        "\n",
        "# Créer un widget Output pour l'affichage des images\n",
        "output = widgets.Output()\n",
        "\n",
        "# Créer un slider\n",
        "slider = widgets.IntSlider(min=0, max=len(images) - 1, step=1, description='Image Index:')\n",
        "\n",
        "# Fonction pour mettre à jour l'image et le nom\n",
        "def update_image(change):\n",
        "    img_index = change['new']  # Utilisation de change['new'] au lieu de change.new\n",
        "    with output:\n",
        "        clear_output(wait=True)  # Effacer l'affichage précédent\n",
        "        plt.figure(figsize=(5,5))  # Ajustez la taille si nécessaire\n",
        "        plt.imshow(images[img_index])  # Afficher la nouvelle image\n",
        "        #plt.title(image_names[img_index])  # Afficher le nom de l'image\n",
        "        plt.axis('off')\n",
        "        if predictions[img_index]>0.5:\n",
        "          classe = 'Classe 1'\n",
        "        else:\n",
        "          classe = 'Classe 0'\n",
        "        plt.title(image_names[img_index] + ':'+classe,fontsize=12)\n",
        "        plt.show()\n",
        "\n",
        "# Observer les changements du slider\n",
        "slider.observe(update_image, names='value')\n",
        "\n",
        "# Afficher le slider et la zone d'affichage\n",
        "display(slider)\n",
        "display(output)\n",
        "\n",
        "# Affichage initial\n",
        "update_image({'new': slider.value})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "demo_cnn_01 (N Classes).ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}